{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19a5599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26390762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gavin\\.conda\\envs\\nlp\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "waste_data = pd.read_csv(\"csv_data/waste_40.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dde7e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (11051 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdbea3c998b4233858c02c17480421c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1008 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chunk_text(text, tokenizer, max_length=512):\n",
    "    # Encode without adding special tokens to get raw token ids\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    # Reserve two tokens for [CLS] and [SEP]\n",
    "    chunk_size = max_length - 2\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size):\n",
    "        chunk_tokens = tokens[i:i+chunk_size]\n",
    "        # Add special tokens back\n",
    "        chunk_tokens = [tokenizer.cls_token_id] + chunk_tokens + [tokenizer.sep_token_id]\n",
    "        chunk_text_str = tokenizer.decode(chunk_tokens, skip_special_tokens=False)\n",
    "        # print(chunk_text_str)  # Debugging: print the chunked text\n",
    "        chunks.append(chunk_text_str)\n",
    "    return chunks\n",
    "\n",
    "def expand_dataset(dataset):\n",
    "    expanded_data = {\"text\": [], \"label\": []}\n",
    "    for example in dataset:\n",
    "        # Split the text into chunks\n",
    "        chunks = chunk_text(example[\"text\"], tokenizer, max_length=512)\n",
    "        # For each chunk, store the chunk and the original label\n",
    "        for chunk in chunks:\n",
    "            expanded_data[\"text\"].append(chunk)\n",
    "            expanded_data[\"label\"].append(example[\"label\"])\n",
    "\n",
    "    return Dataset.from_dict(expanded_data)\n",
    "\n",
    "# Convert your DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(waste_data)\n",
    "\n",
    "# Use the custom function to expand the dataset\n",
    "dataset_chunked = expand_dataset(dataset)\n",
    "\n",
    "# Define a tokenization function for the chunks\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Tokenize the chunked dataset\n",
    "dataset_tokenized = dataset_chunked.map(tokenize_function, batched=True)\n",
    "dataset_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c66cb5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model (optionally loading pre-trained weights)\n",
    "waste_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "# Uncomment and adjust if you have custom weights to load:\n",
    "# model.load_state_dict(torch.load(\"medical_modle.pth\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")), strict=False)\n",
    "waste_model.load_state_dict(torch.load(\"medical_modle.pth\", weights_only=True))\n",
    "waste_model = waste_model.to(device)\n",
    "\n",
    "# Set up evaluation metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    return {\"accuracy\": accuracy[\"accuracy\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8463bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gavin\\.conda\\envs\\nlp\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1323d272f8214618be70d422731bfed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7466, 'grad_norm': 7.198878288269043, 'learning_rate': 1.9936507936507938e-05, 'epoch': 0.03}\n",
      "{'loss': 1.2235, 'grad_norm': 10.171074867248535, 'learning_rate': 1.9873015873015875e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6589, 'grad_norm': 8.94666862487793, 'learning_rate': 1.980952380952381e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7798, 'grad_norm': 7.16019344329834, 'learning_rate': 1.9746031746031748e-05, 'epoch': 0.13}\n",
      "{'loss': 0.647, 'grad_norm': 2.5255496501922607, 'learning_rate': 1.9682539682539684e-05, 'epoch': 0.16}\n",
      "{'loss': 0.615, 'grad_norm': 2.4629263877868652, 'learning_rate': 1.961904761904762e-05, 'epoch': 0.19}\n",
      "{'loss': 0.6593, 'grad_norm': 2.811938524246216, 'learning_rate': 1.9555555555555557e-05, 'epoch': 0.22}\n",
      "{'loss': 0.5681, 'grad_norm': 2.1291096210479736, 'learning_rate': 1.9492063492063494e-05, 'epoch': 0.25}\n",
      "{'loss': 0.5399, 'grad_norm': 2.6759133338928223, 'learning_rate': 1.942857142857143e-05, 'epoch': 0.29}\n",
      "{'loss': 0.5721, 'grad_norm': 4.5783562660217285, 'learning_rate': 1.9365079365079367e-05, 'epoch': 0.32}\n",
      "{'loss': 0.6411, 'grad_norm': 6.879357814788818, 'learning_rate': 1.9301587301587303e-05, 'epoch': 0.35}\n",
      "{'loss': 0.5054, 'grad_norm': 3.083651542663574, 'learning_rate': 1.923809523809524e-05, 'epoch': 0.38}\n",
      "{'loss': 0.6126, 'grad_norm': 3.08418345451355, 'learning_rate': 1.9174603174603176e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4044, 'grad_norm': 2.4927964210510254, 'learning_rate': 1.9111111111111113e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3782, 'grad_norm': 5.230154514312744, 'learning_rate': 1.904761904761905e-05, 'epoch': 0.48}\n",
      "{'loss': 0.412, 'grad_norm': 3.7999045848846436, 'learning_rate': 1.8984126984126986e-05, 'epoch': 0.51}\n",
      "{'loss': 0.5293, 'grad_norm': 3.031562328338623, 'learning_rate': 1.8920634920634923e-05, 'epoch': 0.54}\n",
      "{'loss': 0.44, 'grad_norm': 5.198976993560791, 'learning_rate': 1.885714285714286e-05, 'epoch': 0.57}\n",
      "{'loss': 0.2371, 'grad_norm': 6.013636589050293, 'learning_rate': 1.8793650793650796e-05, 'epoch': 0.6}\n",
      "{'loss': 0.7171, 'grad_norm': 9.0177001953125, 'learning_rate': 1.8730158730158732e-05, 'epoch': 0.63}\n",
      "{'loss': 0.5279, 'grad_norm': 6.584827423095703, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4396, 'grad_norm': 6.756330966949463, 'learning_rate': 1.8603174603174605e-05, 'epoch': 0.7}\n",
      "{'loss': 0.6315, 'grad_norm': 14.124589920043945, 'learning_rate': 1.853968253968254e-05, 'epoch': 0.73}\n",
      "{'loss': 0.5163, 'grad_norm': 11.33935832977295, 'learning_rate': 1.8476190476190478e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3335, 'grad_norm': 4.16144323348999, 'learning_rate': 1.8412698412698415e-05, 'epoch': 0.79}\n",
      "{'loss': 0.4966, 'grad_norm': 3.4138219356536865, 'learning_rate': 1.834920634920635e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3752, 'grad_norm': 6.947218894958496, 'learning_rate': 1.8285714285714288e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3565, 'grad_norm': 11.65114974975586, 'learning_rate': 1.8222222222222224e-05, 'epoch': 0.89}\n",
      "{'loss': 0.653, 'grad_norm': 7.106600284576416, 'learning_rate': 1.815873015873016e-05, 'epoch': 0.92}\n",
      "{'loss': 0.4275, 'grad_norm': 5.270490646362305, 'learning_rate': 1.8095238095238097e-05, 'epoch': 0.95}\n",
      "{'loss': 0.4925, 'grad_norm': 3.3579118251800537, 'learning_rate': 1.8031746031746034e-05, 'epoch': 0.98}\n",
      "{'loss': 0.3971, 'grad_norm': 6.406208515167236, 'learning_rate': 1.796825396825397e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3587, 'grad_norm': 9.926620483398438, 'learning_rate': 1.7904761904761907e-05, 'epoch': 1.05}\n",
      "{'loss': 0.2166, 'grad_norm': 1.918520212173462, 'learning_rate': 1.7841269841269843e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3362, 'grad_norm': 2.5656723976135254, 'learning_rate': 1.7777777777777777e-05, 'epoch': 1.11}\n",
      "{'loss': 0.2067, 'grad_norm': 3.762718915939331, 'learning_rate': 1.7714285714285717e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3307, 'grad_norm': 3.4249751567840576, 'learning_rate': 1.7650793650793653e-05, 'epoch': 1.17}\n",
      "{'loss': 0.2233, 'grad_norm': 10.699896812438965, 'learning_rate': 1.758730158730159e-05, 'epoch': 1.21}\n",
      "{'loss': 0.1088, 'grad_norm': 3.718122959136963, 'learning_rate': 1.7523809523809526e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1359, 'grad_norm': 4.9893927574157715, 'learning_rate': 1.7460317460317463e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2566, 'grad_norm': 6.444501876831055, 'learning_rate': 1.73968253968254e-05, 'epoch': 1.3}\n",
      "{'loss': 0.135, 'grad_norm': 6.346451759338379, 'learning_rate': 1.7333333333333336e-05, 'epoch': 1.33}\n",
      "{'loss': 0.2857, 'grad_norm': 4.291125774383545, 'learning_rate': 1.7269841269841272e-05, 'epoch': 1.37}\n",
      "{'loss': 0.1031, 'grad_norm': 1.8501932621002197, 'learning_rate': 1.720634920634921e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1821, 'grad_norm': 3.5109732151031494, 'learning_rate': 1.7142857142857142e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1564, 'grad_norm': 4.082836151123047, 'learning_rate': 1.707936507936508e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3536, 'grad_norm': 12.69724178314209, 'learning_rate': 1.7015873015873018e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2031, 'grad_norm': 8.148782730102539, 'learning_rate': 1.6952380952380955e-05, 'epoch': 1.52}\n",
      "{'loss': 0.2777, 'grad_norm': 9.52833080291748, 'learning_rate': 1.688888888888889e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2829, 'grad_norm': 15.653879165649414, 'learning_rate': 1.6825396825396828e-05, 'epoch': 1.59}\n",
      "{'loss': 0.1964, 'grad_norm': 11.707281112670898, 'learning_rate': 1.6761904761904764e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0335, 'grad_norm': 0.8260809779167175, 'learning_rate': 1.66984126984127e-05, 'epoch': 1.65}\n",
      "{'loss': 0.1553, 'grad_norm': 9.47614860534668, 'learning_rate': 1.6634920634920637e-05, 'epoch': 1.68}\n",
      "{'loss': 0.0501, 'grad_norm': 7.472808837890625, 'learning_rate': 1.6571428571428574e-05, 'epoch': 1.71}\n",
      "{'loss': 0.204, 'grad_norm': 13.348657608032227, 'learning_rate': 1.6507936507936507e-05, 'epoch': 1.75}\n",
      "{'loss': 0.0821, 'grad_norm': 8.8087739944458, 'learning_rate': 1.6444444444444444e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0486, 'grad_norm': 6.903829097747803, 'learning_rate': 1.6380952380952384e-05, 'epoch': 1.81}\n",
      "{'loss': 0.1353, 'grad_norm': 0.7572770714759827, 'learning_rate': 1.631746031746032e-05, 'epoch': 1.84}\n",
      "{'loss': 0.177, 'grad_norm': 15.46446704864502, 'learning_rate': 1.6253968253968257e-05, 'epoch': 1.87}\n",
      "{'loss': 0.1547, 'grad_norm': 11.708343505859375, 'learning_rate': 1.6190476190476193e-05, 'epoch': 1.9}\n",
      "{'loss': 0.2028, 'grad_norm': 16.178237915039062, 'learning_rate': 1.612698412698413e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0915, 'grad_norm': 8.461792945861816, 'learning_rate': 1.6063492063492066e-05, 'epoch': 1.97}\n",
      "{'loss': 0.0694, 'grad_norm': 3.9874420166015625, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.0}\n",
      "{'loss': 0.0647, 'grad_norm': 0.3400684595108032, 'learning_rate': 1.5936507936507936e-05, 'epoch': 2.03}\n",
      "{'loss': 0.3386, 'grad_norm': 4.5537285804748535, 'learning_rate': 1.5873015873015872e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0311, 'grad_norm': 1.3764948844909668, 'learning_rate': 1.580952380952381e-05, 'epoch': 2.1}\n",
      "{'loss': 0.0714, 'grad_norm': 17.239286422729492, 'learning_rate': 1.5746031746031745e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0789, 'grad_norm': 2.3958547115325928, 'learning_rate': 1.5682539682539685e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0155, 'grad_norm': 0.20042826235294342, 'learning_rate': 1.5619047619047622e-05, 'epoch': 2.19}\n",
      "{'loss': 0.0272, 'grad_norm': 2.6443302631378174, 'learning_rate': 1.555555555555556e-05, 'epoch': 2.22}\n",
      "{'loss': 0.015, 'grad_norm': 1.4328690767288208, 'learning_rate': 1.5492063492063495e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0102, 'grad_norm': 0.68077552318573, 'learning_rate': 1.542857142857143e-05, 'epoch': 2.29}\n",
      "{'loss': 0.1512, 'grad_norm': 3.573707103729248, 'learning_rate': 1.5365079365079368e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0815, 'grad_norm': 7.554238319396973, 'learning_rate': 1.53015873015873e-05, 'epoch': 2.35}\n",
      "{'loss': 0.0114, 'grad_norm': 1.233867883682251, 'learning_rate': 1.523809523809524e-05, 'epoch': 2.38}\n",
      "{'loss': 0.0149, 'grad_norm': 3.0742504596710205, 'learning_rate': 1.5174603174603176e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0678, 'grad_norm': 0.5621068477630615, 'learning_rate': 1.5111111111111112e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0068, 'grad_norm': 0.11777657270431519, 'learning_rate': 1.5047619047619049e-05, 'epoch': 2.48}\n",
      "{'loss': 0.0086, 'grad_norm': 0.4125947654247284, 'learning_rate': 1.4984126984126985e-05, 'epoch': 2.51}\n",
      "{'loss': 0.0078, 'grad_norm': 0.23017790913581848, 'learning_rate': 1.4920634920634922e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0785, 'grad_norm': 3.531867027282715, 'learning_rate': 1.4857142857142858e-05, 'epoch': 2.57}\n",
      "{'loss': 0.0082, 'grad_norm': 0.3382922410964966, 'learning_rate': 1.4793650793650795e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1653, 'grad_norm': 3.6497879028320312, 'learning_rate': 1.4730158730158733e-05, 'epoch': 2.63}\n",
      "{'loss': 0.006, 'grad_norm': 0.08717315644025803, 'learning_rate': 1.4666666666666666e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0146, 'grad_norm': 0.09531456232070923, 'learning_rate': 1.4603174603174603e-05, 'epoch': 2.7}\n",
      "{'loss': 0.4625, 'grad_norm': 7.92440128326416, 'learning_rate': 1.4539682539682541e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0636, 'grad_norm': 0.11695117503404617, 'learning_rate': 1.4476190476190478e-05, 'epoch': 2.76}\n",
      "{'loss': 0.2513, 'grad_norm': 2.889575719833374, 'learning_rate': 1.4412698412698414e-05, 'epoch': 2.79}\n",
      "{'loss': 0.5854, 'grad_norm': 75.33780670166016, 'learning_rate': 1.434920634920635e-05, 'epoch': 2.83}\n",
      "{'loss': 0.0199, 'grad_norm': 1.2247474193572998, 'learning_rate': 1.4285714285714287e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0047, 'grad_norm': 0.09017102420330048, 'learning_rate': 1.4222222222222224e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0091, 'grad_norm': 0.09381979703903198, 'learning_rate': 1.415873015873016e-05, 'epoch': 2.92}\n",
      "{'loss': 0.0705, 'grad_norm': 0.9737957119941711, 'learning_rate': 1.4095238095238097e-05, 'epoch': 2.95}\n",
      "{'loss': 0.3819, 'grad_norm': 43.754058837890625, 'learning_rate': 1.4031746031746032e-05, 'epoch': 2.98}\n",
      "{'loss': 0.1164, 'grad_norm': 0.055972855538129807, 'learning_rate': 1.3968253968253968e-05, 'epoch': 3.02}\n",
      "{'loss': 0.07, 'grad_norm': 29.541057586669922, 'learning_rate': 1.3904761904761905e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0046, 'grad_norm': 0.05712910741567612, 'learning_rate': 1.3841269841269843e-05, 'epoch': 3.08}\n",
      "{'loss': 0.0112, 'grad_norm': 3.23734974861145, 'learning_rate': 1.377777777777778e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0045, 'grad_norm': 0.4727460741996765, 'learning_rate': 1.3714285714285716e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0705, 'grad_norm': 0.072125643491745, 'learning_rate': 1.3650793650793652e-05, 'epoch': 3.17}\n",
      "{'loss': 0.1681, 'grad_norm': 1.138102650642395, 'learning_rate': 1.3587301587301589e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0112, 'grad_norm': 13.275840759277344, 'learning_rate': 1.3523809523809525e-05, 'epoch': 3.24}\n",
      "{'loss': 0.0071, 'grad_norm': 4.446407794952393, 'learning_rate': 1.3460317460317462e-05, 'epoch': 3.27}\n",
      "{'loss': 0.0042, 'grad_norm': 0.10056886821985245, 'learning_rate': 1.3396825396825397e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0037, 'grad_norm': 0.05452179163694382, 'learning_rate': 1.3333333333333333e-05, 'epoch': 3.33}\n",
      "{'loss': 0.1623, 'grad_norm': 8.724936485290527, 'learning_rate': 1.326984126984127e-05, 'epoch': 3.37}\n",
      "{'loss': 0.0043, 'grad_norm': 0.13440027832984924, 'learning_rate': 1.3206349206349206e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0042, 'grad_norm': 0.12476963549852371, 'learning_rate': 1.3142857142857145e-05, 'epoch': 3.43}\n",
      "{'loss': 0.1307, 'grad_norm': 18.418777465820312, 'learning_rate': 1.3079365079365081e-05, 'epoch': 3.46}\n",
      "{'loss': 0.0036, 'grad_norm': 0.08229240775108337, 'learning_rate': 1.3015873015873018e-05, 'epoch': 3.49}\n",
      "{'loss': 0.045, 'grad_norm': 1.7160791158676147, 'learning_rate': 1.2952380952380954e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0137, 'grad_norm': 0.5604916214942932, 'learning_rate': 1.288888888888889e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0034, 'grad_norm': 0.20096519589424133, 'learning_rate': 1.2825396825396827e-05, 'epoch': 3.59}\n",
      "{'loss': 0.0041, 'grad_norm': 0.0472714938223362, 'learning_rate': 1.2761904761904762e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0038, 'grad_norm': 0.2350856214761734, 'learning_rate': 1.2698412698412699e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0036, 'grad_norm': 0.3297206163406372, 'learning_rate': 1.2634920634920635e-05, 'epoch': 3.68}\n",
      "{'loss': 0.0159, 'grad_norm': 0.06074943765997887, 'learning_rate': 1.2571428571428572e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0044, 'grad_norm': 0.07795686274766922, 'learning_rate': 1.2507936507936508e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0036, 'grad_norm': 0.03961866348981857, 'learning_rate': 1.2444444444444446e-05, 'epoch': 3.78}\n",
      "{'loss': 0.0054, 'grad_norm': 0.08036778122186661, 'learning_rate': 1.2380952380952383e-05, 'epoch': 3.81}\n",
      "{'loss': 0.2185, 'grad_norm': 2.756065845489502, 'learning_rate': 1.231746031746032e-05, 'epoch': 3.84}\n",
      "{'loss': 0.007, 'grad_norm': 0.732659637928009, 'learning_rate': 1.2253968253968256e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0765, 'grad_norm': 62.931209564208984, 'learning_rate': 1.2190476190476192e-05, 'epoch': 3.9}\n",
      "{'loss': 0.1505, 'grad_norm': 9.375883102416992, 'learning_rate': 1.2126984126984127e-05, 'epoch': 3.94}\n",
      "{'loss': 0.1632, 'grad_norm': 8.465327262878418, 'learning_rate': 1.2063492063492064e-05, 'epoch': 3.97}\n",
      "{'loss': 0.0653, 'grad_norm': 0.3205786347389221, 'learning_rate': 1.2e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0034, 'grad_norm': 0.04352555796504021, 'learning_rate': 1.1936507936507937e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0905, 'grad_norm': 47.19841384887695, 'learning_rate': 1.1873015873015873e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0028, 'grad_norm': 0.053359225392341614, 'learning_rate': 1.180952380952381e-05, 'epoch': 4.1}\n",
      "{'loss': 0.1638, 'grad_norm': 32.44017028808594, 'learning_rate': 1.1746031746031748e-05, 'epoch': 4.13}\n",
      "{'loss': 0.243, 'grad_norm': 9.866739273071289, 'learning_rate': 1.1682539682539685e-05, 'epoch': 4.16}\n",
      "{'loss': 0.109, 'grad_norm': 30.577423095703125, 'learning_rate': 1.1619047619047621e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0023, 'grad_norm': 0.03865240141749382, 'learning_rate': 1.1555555555555556e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0046, 'grad_norm': 0.25346997380256653, 'learning_rate': 1.1492063492063492e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0304, 'grad_norm': 0.2661500871181488, 'learning_rate': 1.1428571428571429e-05, 'epoch': 4.29}\n",
      "{'loss': 0.0355, 'grad_norm': 1.0621939897537231, 'learning_rate': 1.1365079365079366e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0025, 'grad_norm': 0.050752341747283936, 'learning_rate': 1.1301587301587302e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0051, 'grad_norm': 0.10565350204706192, 'learning_rate': 1.1238095238095239e-05, 'epoch': 4.38}\n",
      "{'loss': 0.002, 'grad_norm': 0.03475624695420265, 'learning_rate': 1.1174603174603175e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0358, 'grad_norm': 0.5626372694969177, 'learning_rate': 1.1111111111111113e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0428, 'grad_norm': 0.6289364695549011, 'learning_rate': 1.104761904761905e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0025, 'grad_norm': 0.23128961026668549, 'learning_rate': 1.0984126984126986e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0058, 'grad_norm': 0.08568073064088821, 'learning_rate': 1.0920634920634921e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0021, 'grad_norm': 0.08285141736268997, 'learning_rate': 1.0857142857142858e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0018, 'grad_norm': 0.03753644600510597, 'learning_rate': 1.0793650793650794e-05, 'epoch': 4.6}\n",
      "{'loss': 0.005, 'grad_norm': 0.046763837337493896, 'learning_rate': 1.073015873015873e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0024, 'grad_norm': 0.06367861479520798, 'learning_rate': 1.0666666666666667e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0162, 'grad_norm': 25.116422653198242, 'learning_rate': 1.0603174603174604e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0019, 'grad_norm': 0.036750100553035736, 'learning_rate': 1.053968253968254e-05, 'epoch': 4.73}\n",
      "{'loss': 0.1163, 'grad_norm': 0.039630476385354996, 'learning_rate': 1.0476190476190477e-05, 'epoch': 4.76}\n",
      "{'loss': 0.0021, 'grad_norm': 0.05654468014836311, 'learning_rate': 1.0412698412698415e-05, 'epoch': 4.79}\n",
      "{'loss': 0.0017, 'grad_norm': 0.035072244703769684, 'learning_rate': 1.0349206349206352e-05, 'epoch': 4.83}\n",
      "{'loss': 0.0023, 'grad_norm': 0.026437684893608093, 'learning_rate': 1.0285714285714285e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0056, 'grad_norm': 0.4742956757545471, 'learning_rate': 1.0222222222222223e-05, 'epoch': 4.89}\n",
      "{'loss': 0.0017, 'grad_norm': 0.029792170971632004, 'learning_rate': 1.015873015873016e-05, 'epoch': 4.92}\n",
      "{'loss': 0.0015, 'grad_norm': 0.02745627611875534, 'learning_rate': 1.0095238095238096e-05, 'epoch': 4.95}\n",
      "{'loss': 0.0028, 'grad_norm': 0.21797163784503937, 'learning_rate': 1.0031746031746033e-05, 'epoch': 4.98}\n",
      "{'loss': 0.0019, 'grad_norm': 0.14633068442344666, 'learning_rate': 9.968253968253969e-06, 'epoch': 5.02}\n",
      "{'loss': 0.0024, 'grad_norm': 0.11545901745557785, 'learning_rate': 9.904761904761906e-06, 'epoch': 5.05}\n",
      "{'loss': 0.0016, 'grad_norm': 0.030438987538218498, 'learning_rate': 9.841269841269842e-06, 'epoch': 5.08}\n",
      "{'loss': 0.0017, 'grad_norm': 0.025032052770256996, 'learning_rate': 9.777777777777779e-06, 'epoch': 5.11}\n",
      "{'loss': 0.0016, 'grad_norm': 0.031564727425575256, 'learning_rate': 9.714285714285715e-06, 'epoch': 5.14}\n",
      "{'loss': 0.0019, 'grad_norm': 0.029985157772898674, 'learning_rate': 9.650793650793652e-06, 'epoch': 5.17}\n",
      "{'loss': 0.0115, 'grad_norm': 7.329855442047119, 'learning_rate': 9.587301587301588e-06, 'epoch': 5.21}\n",
      "{'loss': 0.0014, 'grad_norm': 0.023901773616671562, 'learning_rate': 9.523809523809525e-06, 'epoch': 5.24}\n",
      "{'loss': 0.0016, 'grad_norm': 0.0630599856376648, 'learning_rate': 9.460317460317461e-06, 'epoch': 5.27}\n",
      "{'loss': 0.0017, 'grad_norm': 0.045125219970941544, 'learning_rate': 9.396825396825398e-06, 'epoch': 5.3}\n",
      "{'loss': 0.004, 'grad_norm': 3.9457714557647705, 'learning_rate': 9.333333333333334e-06, 'epoch': 5.33}\n",
      "{'loss': 0.0037, 'grad_norm': 0.3481656312942505, 'learning_rate': 9.26984126984127e-06, 'epoch': 5.37}\n",
      "{'loss': 0.0015, 'grad_norm': 0.02419709973037243, 'learning_rate': 9.206349206349207e-06, 'epoch': 5.4}\n",
      "{'loss': 0.0021, 'grad_norm': 0.04474284499883652, 'learning_rate': 9.142857142857144e-06, 'epoch': 5.43}\n",
      "{'loss': 0.0019, 'grad_norm': 0.02249378338456154, 'learning_rate': 9.07936507936508e-06, 'epoch': 5.46}\n",
      "{'loss': 0.0013, 'grad_norm': 0.023775557056069374, 'learning_rate': 9.015873015873017e-06, 'epoch': 5.49}\n",
      "{'loss': 0.0014, 'grad_norm': 0.06241043284535408, 'learning_rate': 8.952380952380953e-06, 'epoch': 5.52}\n",
      "{'loss': 0.0014, 'grad_norm': 0.03358076140284538, 'learning_rate': 8.888888888888888e-06, 'epoch': 5.56}\n",
      "{'loss': 0.0014, 'grad_norm': 0.02086854912340641, 'learning_rate': 8.825396825396827e-06, 'epoch': 5.59}\n",
      "{'loss': 0.0014, 'grad_norm': 0.03277270868420601, 'learning_rate': 8.761904761904763e-06, 'epoch': 5.62}\n",
      "{'loss': 0.0012, 'grad_norm': 0.026478393003344536, 'learning_rate': 8.6984126984127e-06, 'epoch': 5.65}\n",
      "{'loss': 0.0013, 'grad_norm': 0.051919810473918915, 'learning_rate': 8.634920634920636e-06, 'epoch': 5.68}\n",
      "{'loss': 0.0011, 'grad_norm': 0.0165242999792099, 'learning_rate': 8.571428571428571e-06, 'epoch': 5.71}\n",
      "{'loss': 0.0013, 'grad_norm': 0.018171658739447594, 'learning_rate': 8.507936507936509e-06, 'epoch': 5.75}\n",
      "{'loss': 0.0076, 'grad_norm': 0.634385347366333, 'learning_rate': 8.444444444444446e-06, 'epoch': 5.78}\n",
      "{'loss': 0.001, 'grad_norm': 0.018963593989610672, 'learning_rate': 8.380952380952382e-06, 'epoch': 5.81}\n",
      "{'loss': 0.001, 'grad_norm': 0.01693471148610115, 'learning_rate': 8.317460317460319e-06, 'epoch': 5.84}\n",
      "{'loss': 0.0015, 'grad_norm': 0.10837253928184509, 'learning_rate': 8.253968253968254e-06, 'epoch': 5.87}\n",
      "{'loss': 0.0287, 'grad_norm': 0.02624734677374363, 'learning_rate': 8.190476190476192e-06, 'epoch': 5.9}\n",
      "{'loss': 0.0011, 'grad_norm': 0.019479386508464813, 'learning_rate': 8.126984126984128e-06, 'epoch': 5.94}\n",
      "{'loss': 0.0343, 'grad_norm': 1.3413335084915161, 'learning_rate': 8.063492063492065e-06, 'epoch': 5.97}\n",
      "{'loss': 0.0012, 'grad_norm': 0.021996458992362022, 'learning_rate': 8.000000000000001e-06, 'epoch': 6.0}\n",
      "{'loss': 0.001, 'grad_norm': 0.01706051081418991, 'learning_rate': 7.936507936507936e-06, 'epoch': 6.03}\n",
      "{'loss': 0.0012, 'grad_norm': 0.021536242216825485, 'learning_rate': 7.873015873015873e-06, 'epoch': 6.06}\n",
      "{'loss': 0.0011, 'grad_norm': 0.01731942407786846, 'learning_rate': 7.809523809523811e-06, 'epoch': 6.1}\n",
      "{'loss': 0.0012, 'grad_norm': 0.03182219713926315, 'learning_rate': 7.746031746031747e-06, 'epoch': 6.13}\n",
      "{'loss': 0.0011, 'grad_norm': 0.018372034654021263, 'learning_rate': 7.682539682539684e-06, 'epoch': 6.16}\n",
      "{'loss': 0.0043, 'grad_norm': 0.48327669501304626, 'learning_rate': 7.61904761904762e-06, 'epoch': 6.19}\n",
      "{'loss': 0.0015, 'grad_norm': 0.05075506493449211, 'learning_rate': 7.555555555555556e-06, 'epoch': 6.22}\n",
      "{'loss': 0.0011, 'grad_norm': 0.0188616756349802, 'learning_rate': 7.492063492063493e-06, 'epoch': 6.25}\n",
      "{'loss': 0.0053, 'grad_norm': 9.541295051574707, 'learning_rate': 7.428571428571429e-06, 'epoch': 6.29}\n",
      "{'loss': 0.0009, 'grad_norm': 0.015539887361228466, 'learning_rate': 7.3650793650793666e-06, 'epoch': 6.32}\n",
      "{'loss': 0.001, 'grad_norm': 0.029399558901786804, 'learning_rate': 7.301587301587301e-06, 'epoch': 6.35}\n",
      "{'loss': 0.0011, 'grad_norm': 0.049853548407554626, 'learning_rate': 7.238095238095239e-06, 'epoch': 6.38}\n",
      "{'loss': 0.001, 'grad_norm': 0.01697465404868126, 'learning_rate': 7.174603174603175e-06, 'epoch': 6.41}\n",
      "{'loss': 0.001, 'grad_norm': 0.017374221235513687, 'learning_rate': 7.111111111111112e-06, 'epoch': 6.44}\n",
      "{'loss': 0.0016, 'grad_norm': 0.08148771524429321, 'learning_rate': 7.047619047619048e-06, 'epoch': 6.48}\n",
      "{'loss': 0.0012, 'grad_norm': 0.01959194429218769, 'learning_rate': 6.984126984126984e-06, 'epoch': 6.51}\n",
      "{'loss': 0.0023, 'grad_norm': 0.5018706321716309, 'learning_rate': 6.920634920634921e-06, 'epoch': 6.54}\n",
      "{'loss': 0.028, 'grad_norm': 0.5792529582977295, 'learning_rate': 6.857142857142858e-06, 'epoch': 6.57}\n",
      "{'loss': 0.0009, 'grad_norm': 0.02758757770061493, 'learning_rate': 6.7936507936507944e-06, 'epoch': 6.6}\n",
      "{'loss': 0.0057, 'grad_norm': 0.04142460599541664, 'learning_rate': 6.730158730158731e-06, 'epoch': 6.63}\n",
      "{'loss': 0.0009, 'grad_norm': 0.01653396524488926, 'learning_rate': 6.666666666666667e-06, 'epoch': 6.67}\n",
      "{'loss': 0.0239, 'grad_norm': 0.48637592792510986, 'learning_rate': 6.603174603174603e-06, 'epoch': 6.7}\n",
      "{'loss': 0.0011, 'grad_norm': 0.03191569074988365, 'learning_rate': 6.5396825396825405e-06, 'epoch': 6.73}\n",
      "{'loss': 0.0012, 'grad_norm': 0.05849558860063553, 'learning_rate': 6.476190476190477e-06, 'epoch': 6.76}\n",
      "{'loss': 0.001, 'grad_norm': 0.04766036197543144, 'learning_rate': 6.412698412698414e-06, 'epoch': 6.79}\n",
      "{'loss': 0.0009, 'grad_norm': 0.027037225663661957, 'learning_rate': 6.349206349206349e-06, 'epoch': 6.83}\n",
      "{'loss': 0.0009, 'grad_norm': 0.016446396708488464, 'learning_rate': 6.285714285714286e-06, 'epoch': 6.86}\n",
      "{'loss': 0.001, 'grad_norm': 0.038880202919244766, 'learning_rate': 6.222222222222223e-06, 'epoch': 6.89}\n",
      "{'loss': 0.0008, 'grad_norm': 0.015294350683689117, 'learning_rate': 6.15873015873016e-06, 'epoch': 6.92}\n",
      "{'loss': 0.0027, 'grad_norm': 0.01608208753168583, 'learning_rate': 6.095238095238096e-06, 'epoch': 6.95}\n",
      "{'loss': 0.001, 'grad_norm': 0.02140977419912815, 'learning_rate': 6.031746031746032e-06, 'epoch': 6.98}\n",
      "{'loss': 0.001, 'grad_norm': 0.014448646456003189, 'learning_rate': 5.968253968253968e-06, 'epoch': 7.02}\n",
      "{'loss': 0.0011, 'grad_norm': 0.064115509390831, 'learning_rate': 5.904761904761905e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0009, 'grad_norm': 0.014665360562503338, 'learning_rate': 5.841269841269842e-06, 'epoch': 7.08}\n",
      "{'loss': 0.0014, 'grad_norm': 0.01664292812347412, 'learning_rate': 5.777777777777778e-06, 'epoch': 7.11}\n",
      "{'loss': 0.0008, 'grad_norm': 0.015712762251496315, 'learning_rate': 5.7142857142857145e-06, 'epoch': 7.14}\n",
      "{'loss': 0.0008, 'grad_norm': 0.014320993795990944, 'learning_rate': 5.650793650793651e-06, 'epoch': 7.17}\n",
      "{'loss': 0.0009, 'grad_norm': 0.02568855509161949, 'learning_rate': 5.5873015873015876e-06, 'epoch': 7.21}\n",
      "{'loss': 0.0011, 'grad_norm': 0.020141884684562683, 'learning_rate': 5.523809523809525e-06, 'epoch': 7.24}\n",
      "{'loss': 0.0008, 'grad_norm': 0.012750983238220215, 'learning_rate': 5.460317460317461e-06, 'epoch': 7.27}\n",
      "{'loss': 0.0008, 'grad_norm': 0.013171662576496601, 'learning_rate': 5.396825396825397e-06, 'epoch': 7.3}\n",
      "{'loss': 0.001, 'grad_norm': 0.03689669445157051, 'learning_rate': 5.333333333333334e-06, 'epoch': 7.33}\n",
      "{'loss': 0.0007, 'grad_norm': 0.012984947301447392, 'learning_rate': 5.26984126984127e-06, 'epoch': 7.37}\n",
      "{'loss': 0.0008, 'grad_norm': 0.014633998274803162, 'learning_rate': 5.2063492063492076e-06, 'epoch': 7.4}\n",
      "{'loss': 0.0033, 'grad_norm': 0.012785675935447216, 'learning_rate': 5.142857142857142e-06, 'epoch': 7.43}\n",
      "{'loss': 0.0234, 'grad_norm': 0.5363373160362244, 'learning_rate': 5.07936507936508e-06, 'epoch': 7.46}\n",
      "{'loss': 0.0008, 'grad_norm': 0.015406777150928974, 'learning_rate': 5.015873015873016e-06, 'epoch': 7.49}\n",
      "{'loss': 0.0009, 'grad_norm': 0.011422858573496342, 'learning_rate': 4.952380952380953e-06, 'epoch': 7.52}\n",
      "{'loss': 0.0008, 'grad_norm': 0.016573591157794, 'learning_rate': 4.888888888888889e-06, 'epoch': 7.56}\n",
      "{'loss': 0.001, 'grad_norm': 0.05612741783261299, 'learning_rate': 4.825396825396826e-06, 'epoch': 7.59}\n",
      "{'loss': 0.0008, 'grad_norm': 0.014491673558950424, 'learning_rate': 4.761904761904762e-06, 'epoch': 7.62}\n",
      "{'loss': 0.0247, 'grad_norm': 0.014707637950778008, 'learning_rate': 4.698412698412699e-06, 'epoch': 7.65}\n",
      "{'loss': 0.002, 'grad_norm': 0.019173847511410713, 'learning_rate': 4.634920634920635e-06, 'epoch': 7.68}\n",
      "{'loss': 0.001, 'grad_norm': 0.03670515865087509, 'learning_rate': 4.571428571428572e-06, 'epoch': 7.71}\n",
      "{'loss': 0.0008, 'grad_norm': 0.01706094667315483, 'learning_rate': 4.5079365079365085e-06, 'epoch': 7.75}\n",
      "{'loss': 0.0011, 'grad_norm': 0.010871503502130508, 'learning_rate': 4.444444444444444e-06, 'epoch': 7.78}\n",
      "{'loss': 0.0008, 'grad_norm': 0.015009703114628792, 'learning_rate': 4.3809523809523815e-06, 'epoch': 7.81}\n",
      "{'loss': 0.0009, 'grad_norm': 0.01761135272681713, 'learning_rate': 4.317460317460318e-06, 'epoch': 7.84}\n",
      "{'loss': 0.0008, 'grad_norm': 0.016728386282920837, 'learning_rate': 4.2539682539682546e-06, 'epoch': 7.87}\n",
      "{'loss': 0.0008, 'grad_norm': 0.012590667232871056, 'learning_rate': 4.190476190476191e-06, 'epoch': 7.9}\n",
      "{'loss': 0.0007, 'grad_norm': 0.010613424703478813, 'learning_rate': 4.126984126984127e-06, 'epoch': 7.94}\n",
      "{'loss': 0.0007, 'grad_norm': 0.01321322564035654, 'learning_rate': 4.063492063492064e-06, 'epoch': 7.97}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011715097352862358, 'learning_rate': 4.000000000000001e-06, 'epoch': 8.0}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011536329053342342, 'learning_rate': 3.936507936507936e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0007, 'grad_norm': 0.013171397149562836, 'learning_rate': 3.873015873015874e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0008, 'grad_norm': 0.01930396258831024, 'learning_rate': 3.80952380952381e-06, 'epoch': 8.1}\n",
      "{'loss': 0.0008, 'grad_norm': 0.020929226651787758, 'learning_rate': 3.7460317460317463e-06, 'epoch': 8.13}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011868695728480816, 'learning_rate': 3.6825396825396833e-06, 'epoch': 8.16}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011471325531601906, 'learning_rate': 3.6190476190476194e-06, 'epoch': 8.19}\n",
      "{'loss': 0.0009, 'grad_norm': 0.012090262956917286, 'learning_rate': 3.555555555555556e-06, 'epoch': 8.22}\n",
      "{'loss': 0.0008, 'grad_norm': 0.043098561465740204, 'learning_rate': 3.492063492063492e-06, 'epoch': 8.25}\n",
      "{'loss': 0.0232, 'grad_norm': 0.5974313020706177, 'learning_rate': 3.428571428571429e-06, 'epoch': 8.29}\n",
      "{'loss': 0.001, 'grad_norm': 0.033966295421123505, 'learning_rate': 3.3650793650793655e-06, 'epoch': 8.32}\n",
      "{'loss': 0.0006, 'grad_norm': 0.010861645452678204, 'learning_rate': 3.3015873015873016e-06, 'epoch': 8.35}\n",
      "{'loss': 0.0007, 'grad_norm': 0.012241848744452, 'learning_rate': 3.2380952380952385e-06, 'epoch': 8.38}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011152004823088646, 'learning_rate': 3.1746031746031746e-06, 'epoch': 8.41}\n",
      "{'loss': 0.0007, 'grad_norm': 0.013084867037832737, 'learning_rate': 3.1111111111111116e-06, 'epoch': 8.44}\n",
      "{'loss': 0.0009, 'grad_norm': 0.019750479608774185, 'learning_rate': 3.047619047619048e-06, 'epoch': 8.48}\n",
      "{'loss': 0.0214, 'grad_norm': 0.429015576839447, 'learning_rate': 2.984126984126984e-06, 'epoch': 8.51}\n",
      "{'loss': 0.0008, 'grad_norm': 0.014030144549906254, 'learning_rate': 2.920634920634921e-06, 'epoch': 8.54}\n",
      "{'loss': 0.0008, 'grad_norm': 0.020401503890752792, 'learning_rate': 2.8571428571428573e-06, 'epoch': 8.57}\n",
      "{'loss': 0.0007, 'grad_norm': 0.012684655375778675, 'learning_rate': 2.7936507936507938e-06, 'epoch': 8.6}\n",
      "{'loss': 0.0059, 'grad_norm': 0.6918738484382629, 'learning_rate': 2.7301587301587303e-06, 'epoch': 8.63}\n",
      "{'loss': 0.0008, 'grad_norm': 0.018840404227375984, 'learning_rate': 2.666666666666667e-06, 'epoch': 8.67}\n",
      "{'loss': 0.0009, 'grad_norm': 0.02212531492114067, 'learning_rate': 2.6031746031746038e-06, 'epoch': 8.7}\n",
      "{'loss': 0.0007, 'grad_norm': 0.017769845202565193, 'learning_rate': 2.53968253968254e-06, 'epoch': 8.73}\n",
      "{'loss': 0.0008, 'grad_norm': 0.011019009165465832, 'learning_rate': 2.4761904761904764e-06, 'epoch': 8.76}\n",
      "{'loss': 0.0007, 'grad_norm': 0.010901154950261116, 'learning_rate': 2.412698412698413e-06, 'epoch': 8.79}\n",
      "{'loss': 0.0007, 'grad_norm': 0.012084090150892735, 'learning_rate': 2.3492063492063494e-06, 'epoch': 8.83}\n",
      "{'loss': 0.0007, 'grad_norm': 0.01314657460898161, 'learning_rate': 2.285714285714286e-06, 'epoch': 8.86}\n",
      "{'loss': 0.0008, 'grad_norm': 0.01410618331283331, 'learning_rate': 2.222222222222222e-06, 'epoch': 8.89}\n",
      "{'loss': 0.002, 'grad_norm': 0.028944706544280052, 'learning_rate': 2.158730158730159e-06, 'epoch': 8.92}\n",
      "{'loss': 0.0011, 'grad_norm': 0.012618845328688622, 'learning_rate': 2.0952380952380955e-06, 'epoch': 8.95}\n",
      "{'loss': 0.0007, 'grad_norm': 0.010293211787939072, 'learning_rate': 2.031746031746032e-06, 'epoch': 8.98}\n",
      "{'loss': 0.0007, 'grad_norm': 0.013815229758620262, 'learning_rate': 1.968253968253968e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0008, 'grad_norm': 0.015684235841035843, 'learning_rate': 1.904761904761905e-06, 'epoch': 9.05}\n",
      "{'loss': 0.0008, 'grad_norm': 0.01810833439230919, 'learning_rate': 1.8412698412698416e-06, 'epoch': 9.08}\n",
      "{'loss': 0.0007, 'grad_norm': 0.018673889338970184, 'learning_rate': 1.777777777777778e-06, 'epoch': 9.11}\n",
      "{'loss': 0.0008, 'grad_norm': 0.01430635154247284, 'learning_rate': 1.7142857142857145e-06, 'epoch': 9.14}\n",
      "{'loss': 0.0008, 'grad_norm': 0.012373575940728188, 'learning_rate': 1.6507936507936508e-06, 'epoch': 9.17}\n",
      "{'loss': 0.0008, 'grad_norm': 0.02409600466489792, 'learning_rate': 1.5873015873015873e-06, 'epoch': 9.21}\n",
      "{'loss': 0.0208, 'grad_norm': 0.48508673906326294, 'learning_rate': 1.523809523809524e-06, 'epoch': 9.24}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011215202510356903, 'learning_rate': 1.4603174603174606e-06, 'epoch': 9.27}\n",
      "{'loss': 0.0008, 'grad_norm': 0.033099930733442307, 'learning_rate': 1.3968253968253969e-06, 'epoch': 9.3}\n",
      "{'loss': 0.0007, 'grad_norm': 0.02195965312421322, 'learning_rate': 1.3333333333333334e-06, 'epoch': 9.33}\n",
      "{'loss': 0.0006, 'grad_norm': 0.010998851619660854, 'learning_rate': 1.26984126984127e-06, 'epoch': 9.37}\n",
      "{'loss': 0.0006, 'grad_norm': 0.012040744535624981, 'learning_rate': 1.2063492063492065e-06, 'epoch': 9.4}\n",
      "{'loss': 0.0007, 'grad_norm': 0.014966273680329323, 'learning_rate': 1.142857142857143e-06, 'epoch': 9.43}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011887315660715103, 'learning_rate': 1.0793650793650795e-06, 'epoch': 9.46}\n",
      "{'loss': 0.0006, 'grad_norm': 0.010286669246852398, 'learning_rate': 1.015873015873016e-06, 'epoch': 9.49}\n",
      "{'loss': 0.0008, 'grad_norm': 0.014611751772463322, 'learning_rate': 9.523809523809525e-07, 'epoch': 9.52}\n",
      "{'loss': 0.0006, 'grad_norm': 0.011434457264840603, 'learning_rate': 8.88888888888889e-07, 'epoch': 9.56}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011027531698346138, 'learning_rate': 8.253968253968254e-07, 'epoch': 9.59}\n",
      "{'loss': 0.0006, 'grad_norm': 0.011037150397896767, 'learning_rate': 7.61904761904762e-07, 'epoch': 9.62}\n",
      "{'loss': 0.0006, 'grad_norm': 0.018627407029271126, 'learning_rate': 6.984126984126984e-07, 'epoch': 9.65}\n",
      "{'loss': 0.0007, 'grad_norm': 0.012871273793280125, 'learning_rate': 6.34920634920635e-07, 'epoch': 9.68}\n",
      "{'loss': 0.0226, 'grad_norm': 0.010577542707324028, 'learning_rate': 5.714285714285715e-07, 'epoch': 9.71}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011985265649855137, 'learning_rate': 5.07936507936508e-07, 'epoch': 9.75}\n",
      "{'loss': 0.0007, 'grad_norm': 0.01608937606215477, 'learning_rate': 4.444444444444445e-07, 'epoch': 9.78}\n",
      "{'loss': 0.0007, 'grad_norm': 0.012980996631085873, 'learning_rate': 3.80952380952381e-07, 'epoch': 9.81}\n",
      "{'loss': 0.0009, 'grad_norm': 0.013063355349004269, 'learning_rate': 3.174603174603175e-07, 'epoch': 9.84}\n",
      "{'loss': 0.0007, 'grad_norm': 0.016132794320583344, 'learning_rate': 2.53968253968254e-07, 'epoch': 9.87}\n",
      "{'loss': 0.0006, 'grad_norm': 0.01176952850073576, 'learning_rate': 1.904761904761905e-07, 'epoch': 9.9}\n",
      "{'loss': 0.002, 'grad_norm': 0.011201047338545322, 'learning_rate': 1.26984126984127e-07, 'epoch': 9.94}\n",
      "{'loss': 0.0012, 'grad_norm': 0.10563475638628006, 'learning_rate': 6.34920634920635e-08, 'epoch': 9.97}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011491046287119389, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'train_runtime': 325.0302, 'train_samples_per_second': 31.013, 'train_steps_per_second': 1.938, 'train_loss': 0.09321409591384941, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=630, training_loss=0.09321409591384941, metrics={'train_runtime': 325.0302, 'train_samples_per_second': 31.013, 'train_steps_per_second': 1.938, 'total_flos': 1335271378452480.0, 'train_loss': 0.09321409591384941, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model (optionally loading pre-trained weights)\n",
    "waste_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "# Uncomment and adjust if you have custom weights to load:\n",
    "# model.load_state_dict(torch.load(\"medical_modle.pth\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")), strict=False)\n",
    "waste_model.load_state_dict(torch.load(\"medical_modle.pth\", weights_only=True))\n",
    "waste_model = waste_model.to(device)\n",
    "\n",
    "# Set up evaluation metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    return {\"accuracy\": accuracy[\"accuracy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b02f3",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa701968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing abah 2022.pdf...\n",
      "Processing abdurrahman 2020.pdf...\n",
      "Processing adebiyi 2020.pdf...\n",
      "Processing bajyacharya 2021.pdf...\n",
      "Processing Das 2022.pdf...\n",
      "Processing Lin 2013.pdf...\n",
      "Processing tabian 2021.pdf...\n",
      "Processing timonen 2021.pdf...\n",
      "Processing uttajug 2021.pdf...\n",
      "Processing uttajug 2022.pdf...\n",
      "Processing vreeland 2016.pdf...\n",
      "Processing wu 2006.pdf...\n",
      "Processing zak 2021.pdf...\n",
      "Processing zakey 2008.pdf...\n",
      "Processing zalakeviciute 2020.pdf...\n",
      "Processing zalakeviciute 2021.pdf...\n",
      "Processing zalasiewicz 2019.pdf...\n",
      "Processing zalel 2015.pdf...\n",
      "Processing zalzal 2024.pdf...\n",
      "Processing zhang 2023.pdf...\n",
      "Predictions saved to csv_data/test_predictions_40.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        full_text = \"\"\n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc.load_page(page_num)\n",
    "            full_text += page.get_text().strip()\n",
    "        return full_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def predict_label_for_pdf(pdf_path, model, tokenizer, device):\n",
    "    # Extract text from the PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text.strip():\n",
    "        print(f\"No text extracted from {pdf_path}\")\n",
    "        return None\n",
    "\n",
    "    # Split the full text into chunks that do not exceed 512 tokens\n",
    "    chunks = chunk_text(text, tokenizer, max_length=512)\n",
    "    \n",
    "    # Store logits from each chunk\n",
    "    all_logits = []\n",
    "    for chunk in chunks:\n",
    "        # Tokenize each chunk (padding and truncation ensure fixed size input)\n",
    "        inputs = tokenizer(chunk, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits  # shape [1, num_labels]\n",
    "            all_logits.append(logits)\n",
    "    \n",
    "    # Aggregate predictions by averaging the logits across chunks.\n",
    "    # You can also consider majority voting on the predicted labels.\n",
    "    aggregated_logits = torch.mean(torch.cat(all_logits, dim=0), dim=0, keepdim=True)  # shape [1, num_labels]\n",
    "    predicted_label = torch.argmax(aggregated_logits, dim=1).item()\n",
    "    return predicted_label\n",
    "\n",
    "def process_pdfs_after_training(directory_path, output_csv, model, tokenizer, device):\n",
    "    results = []\n",
    "    \n",
    "    # Iterate through all PDF files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            \n",
    "            # Predict label for the PDF (aggregating over chunks)\n",
    "            predicted_label = predict_label_for_pdf(pdf_path, model, tokenizer, device)\n",
    "            if predicted_label is None:\n",
    "                continue  # Skip files with no extracted text\n",
    "            \n",
    "            # Convert numeric prediction to string label\n",
    "            new_label = \"YES\" if predicted_label == 1 else \"NO\"\n",
    "            results.append({\"filename\": filename, \"predicted_label\": new_label})\n",
    "    \n",
    "    # Save the results to a CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Predictions saved to {output_csv}\")\n",
    "\n",
    "pdfs_dir = \"pdf_data/test\"\n",
    "output_csv_path = \"csv_data/test_predictions_40.csv\"\n",
    "\n",
    "process_pdfs_after_training(\n",
    "    directory_path=pdfs_dir,\n",
    "    output_csv=output_csv_path,\n",
    "    model=waste_model,      \n",
    "    tokenizer=tokenizer,     \n",
    "    device=device           \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
